{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Environment information from Kaggle\nYou can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \nYou can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"},{"metadata":{},"cell_type":"markdown","source":"## Imports\nWe'll keep our imports here for easier reference"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd  # To easily read csv files (image filenames & label)\nimport os  # For building paths\nimport json  # To parse the label map\nfrom torch.utils.data import Dataset, DataLoader  # We'll build a custom dataset & dataloader\nimport torchvision.transforms  # To transform our images to the shape needed by torch\nimport torch\nfrom PIL import Image  # Python Image Library for reading our image files","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## GPU Use\nSee if we have an available CUDA-enabled GPU. We'll move data/models to the selected device later on."},{"metadata":{"trusted":true},"cell_type":"code","source":"if not torch.cuda.is_available():\n    print('No CUDA-enabled GPU detected. Please enable GPU acceleration for faster training.')\n    device = 'cpu'\nelse:\n    device = torch.device('cuda:0')\n    print(f'CUDA-enabled GPU detected. Using device: {device}')","execution_count":2,"outputs":[{"output_type":"stream","text":"CUDA-enabled GPU detected. Using device: cuda:0\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"INPUT_PATH = os.path.join(os.sep, 'kaggle', 'input', 'cassava-leaf-disease-classification')\nTRAIN_IMAGES_PATH = os.path.join(INPUT_PATH, 'train_images')\nTEST_IMAGES_PATH = os.path.join(INPUT_PATH, 'test_images')\n\n# Explore what we have\n\n# train.csv contains image filenames & their class label corresponding to the leaf disease (or healthy) \ntrain_labels = pd.read_csv(os.path.join(INPUT_PATH, 'train.csv'))\n# print(train_labels.head())\n# print(train_labels['image_id'][[0, 2]].values)\nprint(f'Number of training images: {train_labels.shape[0]}')","execution_count":3,"outputs":[{"output_type":"stream","text":"Number of training images: 21397\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Load label meanings\nThe file label_num_to_disease_map.json maps our class labels (integers) to the actual meaning (disease name or healthy)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"with open(os.path.join(INPUT_PATH, 'label_num_to_disease_map.json')) as json_file:\n    LABEL_MAP = json.load(json_file)\n    \nfor k, v in LABEL_MAP.items():\n    print(f'{k}: {v}')","execution_count":4,"outputs":[{"output_type":"stream","text":"0: Cassava Bacterial Blight (CBB)\n1: Cassava Brown Streak Disease (CBSD)\n2: Cassava Green Mottle (CGM)\n3: Cassava Mosaic Disease (CMD)\n4: Healthy\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Custom Dataset\nWe'll need a custom dataset, inheriting from `torch.utils.data.Dataset`, that can load images & labels as needed. We'll go ahead & transform images to tensors in this class as well."},{"metadata":{"trusted":true},"cell_type":"code","source":"class TrainingDataset(Dataset):\n    def __init__(self, train_images_path):\n        self.transform = torchvision.transforms.ToTensor()\n        self.labels_df = pd.read_csv(os.path.join(INPUT_PATH, 'train.csv'))\n        self.images_path = train_images_path\n        \n    def __len__(self):\n        return self.labels_df.shape[0]\n    \n    def __getitem__(self, idx):            \n        img_name = os.path.join(self.images_path, self.labels_df['image_id'].iloc[idx])\n        img = self.transform(Image.open(img_name))\n        label = self.labels_df['label'][idx]\n        \n        return img, label","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Test that our dataset works\nHere we just instantiate our dataset & confirm that we're getting what we expect from it"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = TrainingDataset(TRAIN_IMAGES_PATH)\n\nassert len(train_dataset) == train_labels.shape[0]\n\nfor i in range(5):\n    img, label = train_dataset[i]\n    print(f'Image {i}')\n    print(f'\\ttype: {type(img)}, shape: {img.shape}, label: {label}')","execution_count":6,"outputs":[{"output_type":"stream","text":"Image 0\n\ttype: <class 'torch.Tensor'>, shape: torch.Size([3, 600, 800]), label: 0\nImage 1\n\ttype: <class 'torch.Tensor'>, shape: torch.Size([3, 600, 800]), label: 3\nImage 2\n\ttype: <class 'torch.Tensor'>, shape: torch.Size([3, 600, 800]), label: 1\nImage 3\n\ttype: <class 'torch.Tensor'>, shape: torch.Size([3, 600, 800]), label: 1\nImage 4\n\ttype: <class 'torch.Tensor'>, shape: torch.Size([3, 600, 800]), label: 3\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Use DataLoader\nThe DataLoader class gives us batching. We'll also need a custom callback to pin memory. Pinned memory is faster when transferring from CPU to GPU which we'll be doing to speed up training."},{"metadata":{"trusted":true},"cell_type":"code","source":"class ImageBatch:\n    def __init__(self, data):\n        self.images = torch.stack([datum[0] for datum in data])\n        self.labels = [datum[1] for datum in data]\n        \n    def pin_memory(self):\n        self.images = self.images.pin_memory()\n        return self\n    \n        \ndef collate_wrapper(batch):\n    return ImageBatch(batch)","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Test DataLoader\nBelow we check that our data loader is returning what we expect and that our memory is actually pinned. Note that our memory will not be pinned if our device is a CPU rather than GPU."},{"metadata":{"trusted":true},"cell_type":"code","source":"dl = DataLoader(train_dataset, batch_size=10, collate_fn=collate_wrapper, pin_memory=True)\nfor batch_index, image_batch in enumerate(dl):\n    if batch_index == 5:\n        break\n    print(f'Batch {batch_index} size: {len(image_batch.images[0])}. is_pinned: {image_batch.images[0].is_pinned()}')","execution_count":8,"outputs":[{"output_type":"stream","text":"Batch 0 size: 3. is_pinned: True\nBatch 1 size: 3. is_pinned: True\nBatch 2 size: 3. is_pinned: True\nBatch 3 size: 3. is_pinned: True\nBatch 4 size: 3. is_pinned: True\n","name":"stdout"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}